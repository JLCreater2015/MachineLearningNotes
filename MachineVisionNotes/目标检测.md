---
title: 目标检测
tags: 目标检测,R-CNN,YOLO,SSD
grammar_cjkRuby: true
---

#### 一、目标检测综述

##### 1、什么是目标检测？
**目标检测** 的任务是找出图像中所有感兴趣的目标（物体），确定它们的位置和大小，是机器视觉领域的核心问题之一。由于各类物体有不同的外观，形状，姿态，加上成像时光照，遮挡等因素的干扰，目标检测一直是机器视觉领域最具有挑战性的问题。

计算机视觉中关于图像识别有四大类任务：

 1. 分类-Classification：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。
 2. 定位-Location：解决“在哪里？”的问题，即定位出这个目标的的位置。
 3. 检测-Detection：解决“是什么？在哪里？”的问题，即定位出这个目标的的位置并且知道目标物是什么。
 4. 分割-Segmentation：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。

##### 2、目标检测要解决的核心问题
除了图像分类之外，目标检测要解决的核心问题是：

 1. 目标可能出现在图像的任何位置。
 2. 目标有各种不同的大小。
 3. 目标可能有各种不同的形状。
 
如果用矩形框来定义目标，则矩形有不同的宽高比。由于目标的宽高比不同，因此采用经典的滑动窗口+图像缩放的方案解决通用目标检测问题的成本太高。

##### 3、目标检测最新进展

![enter description here](./images/target_detection.png)

![enter description here](./images/11.png)

#### 二、传统方法

##### 1、滑窗法
滑动窗口检测器是一种暴力检测方法，从左到右，从上到下滑动窗口，然后利用分类识别目标。这里使用不同大小的窗口，因为一张图片可能展示从不同距离观测检测出不同的目标类型。首先来看一下滑窗法的物体检测流程图：

![enter description here](./images/12.png)

　　通过滑窗法流程图可以很清晰理解其主要思路：首先对输入图像进行不同窗口大小的滑窗进行从左往右、从上到下的滑动。每次滑动时候对当前窗口执行分类器(分类器是事先训练好的)。如果当前窗口得到较高的分类概率，则认为检测到了物体。对每个不同窗口大小的滑窗都进行检测后，会得到不同窗口检测到的物体标记，这些窗口大小会存在重复较高的部分，最后采用非极大值抑制(Non-Maximum Suppression, NMS)的方法进行筛选。最终，经过NMS筛选后获得检测到的物体。
  
  滑动窗口从图像中可能剪切出不同大小的图像块，但是很多分类器只取固定大小的图像，所以这些图像是经过变形转换的。但是这样做并不影响准确率，因为分类器可以处理变形后的图像。 变形图像被输入到CNN中，提取4096个特征，然后使用SVM和一个线性分类器来识别分类和边界框。
  
![enter description here](./images/13.png)
  
　　滑窗法简单易于理解，但是不同窗口大小进行图像全局搜索导致效率低下，而且设计窗口大小时候还需要考虑物体的长宽比。所以，对于实时性要求较高的分类器，不推荐使用滑窗法。 
　　 
##### 2、Region Proposal方法

Region Proposal方法比传统的滑动窗口方法获取的质量要更高。比较常用的Region Proposal方法有：SelectiveSearch(SS，选择性搜索)、Edge Boxes（EB）。

基于Region Proposal目标检测算法的步骤如下：

![enter description here](./images/16.png)

其中边框回归（Bouding Box Regression）：是对RegionProposal进行纠正的线性回归算法，目的是为了让Region Proposal提取到的窗口与目标窗口（Ground Truth）更加吻合。

###### （1）、SelectiveSearch(SS，选择性搜索)

为了在滑动窗口检测器的基础上提高搜索速度，可以采用候选区域方法(region proposal method)创建目标检测的感兴趣区域(ROI)。在选择性搜索中，首先将每个像素作为一组，然后计算每一组的纹理，将两个最接近的组结合起来，我们通常对较小的组先分组，合并区域知道所有区域都合并在一起。看一下选择搜索的物体检测流程图：

![enter description here](./images/15_1.png)

　　滑窗法类似穷举进行图像子区域搜索，但是一般情况下图像中大部分子区域是没有物体的。学者们自然而然想到只对图像中最有可能包含物体的区域进行搜索以此来提高计算效率。选择搜索方法是当下最为熟知的图像bouding boxes提取算法，由Koen E.A于2011年提出，具体详见论文。下面大致说一下选择搜索算法的过程：
　　选择搜索算法的主要观点：图像中物体可能存在的区域应该是有某些相似性或者连续性区域的。因此，选择搜索基于上面这一想法采用子区域合并的方法进行提取bounding boxes候选边界框。首先，对输入图像进行分割算法产生许多小的子区域。其次，根据这些子区域之间相似性(相似性标准主要有颜色、纹理、大小等等)进行区域合并，不断的进行区域迭代合并。每次迭代过程中对这些合并的子区域做bounding boxes(外切矩形)，这些子区域外切矩形就是通常所说的候选框。

选择搜索优点： 
 1. 计算效率优于滑窗法。 
 2. 由于采用子区域合并策略，所以可以包含各种大小的疑似物体框。 
 3. 合并区域相似的指标多样性，提高了检测物体的概率。

###### （2）、Edge Boxes（EB）

**论文《Edge Boxes: Locating Object Proposals from Edges》**

利用边缘信息（Edge），确定框框内的轮廓个数和与框框边缘重叠的轮廓个数（这点很重要，如果我能够清楚的知道一个框框内完全包含的轮廓个数，那么目标有很大可能性，就在这个框中），并基于此对框框进行评分，进一步根据得分的高低顺序确定proposal信息（由大小，长宽比，位置构成）。而后续工作就是在proposal内部运行相关检测算法。

下面试着详细介绍本文算法流程：

![enter description here](./images/20.jpg)

首先，第一行是原图，第二行是基于文献《Structured Forests for Fast Edge Detection》所提出的结构化边缘检测算法，得到的边缘图像，这时的边缘图像显得很紧密，需要用NMS进一步处理得到一个相对稀疏的边缘图像。

其次，第三行中，本来灰色的边缘变成了五颜六色的边缘，其实这些五颜六色的边缘是基于某种策略，将边缘点集合起来得到的N多个小段，论文中，叫做 edge group。所采用的的策略是：将近乎在一条直线上的边缘点，集中起来形成一个edge group，具体的做法是，不停地寻找8连通的边缘点，直到两两边缘点之间的方向角度差值的和大于 `!$\pi/2$`，这样便得到了 `!$N$` 多个edge group。

再其次，得到 `!$N$` 个edge group之后，还要进一步计算两两edge group之间的相似度，相似度的公式很简单，如下：

```mathjax!
$$
a(s_i,s_j) = |cos(\theta_i - \theta_{ij})cos(\theta_j - \theta_{ij})|^{\gamma}
$$
```

这样变使得，如果两个edge group越在一条直线上，上述公式计算得到的相似度就越高，反之亦然。作者之所以引入edge group概念，是为了确定轮廓个数做准备，因为一个轮廓中的所有edge group当然是最相似的，这点可以在纸上画画，十分明显。

最后，让我们看看作者是怎么根据edge group来确定轮廓的。作者的做法在我看起来很奇葩，他给每一个edge group一个权值，换句话说，打个分数，然后把权值均为1的edge group归为框框内轮廓上的一部分，把权值为0的edge group归为框框外或者与框框边界重叠的轮廓的一部分。采用了一个数学公式达到了上述目的，如下：

```mathjax!
$$
w_b(s_i) = 1 - max_{T} \prod_j^{|T| - 1} a(t_j,t_{j+1})
$$
```

其中，T 是指从框框的边缘开始到达 `!$s_i$` 的edge group序列集合，当然，会有很多个 T，看到没，它的目标就是从这么多的路径T中，寻找相似度最高的路径，这就是传说中的轮廓。值得注意的是，在某路径 T上，一旦出现相似度为 0（这很容易出现）的情况，这条路径T就废弃了，所以想找到那个合适的T，真的很快。

Edgebox进行目标检测的思路为：首先利用结构化的方法检测出边缘，并利用非极大值抑制对边缘进行筛选；然后基于某种策略将似乎在一条直线上的边缘点集合成若干个edge group，并计算edge group之间的相似度，越是在同一直线上的edge group，其相似度越高。再通过edge group来确定轮廓数，实现策略为给每个edge group计算一个权值，将权值为1的edge group归为proposal内轮廓上的一部分，将权值为 0 的edge group归为proposal外或proposal框重叠的一部分，由此便提取得到proposal，并对proposal进行评分，选取得分最高的proposal作为最后的检测输出。但是该算法有一个明显的缺陷是当一幅图像中包含多个相同的检测目标时，其得分最高的proposal几乎包含整幅图像，而不是单独的目标。原因在于，其不是基于“学习”的算法，没有训练的过程，也就没有具体的针对目标的模型，故这使得其在进行单一类别多目标检测时效果不佳。